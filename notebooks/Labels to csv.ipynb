{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an intermediate csv file for the objects we are trying to identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import get_data_file\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and select classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_file = get_data_file('raw', 'annotations/classes.txt')\n",
    "annotation_files = set(glob(get_data_file('raw','annotations/*.txt')))\n",
    "annotation_files.remove(class_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(class_file) as readable:\n",
    "    classes = { i:tag.strip() for i, tag in enumerate(readable) }\n",
    "    rev_class = {v:k for k,v in classes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_keep = set([\"valentina\", \"valentina-negra\", \"botaneraaa\"])\n",
    "ids_to_keep = set([ rev_class[k] for k in classes_to_keep ])\n",
    "print(ids_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_yolo_to_values(x1, y1, width, height, shape):\n",
    "    img_width, img_height = shape\n",
    "    x_rect = (x1 - width/2) * img_width\n",
    "    y_rect = (y1 - height/2) * img_height\n",
    "    width_rect = width * img_width\n",
    "    height_rect = height * img_height\n",
    "    return int(x_rect), int(y_rect), int(width_rect), int(height_rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(image):\n",
    "    image = get_data_file('raw', f'images/{image}')\n",
    "    jpg = image + \".jpg\"\n",
    "    if os.path.exists(jpg):\n",
    "        return jpg\n",
    "    jpeg = image + \".jpeg\"\n",
    "    if os.path.exists(jpeg):\n",
    "        return jpeg\n",
    "    png = image + \".png\"\n",
    "    if os.path.exists(png):\n",
    "        return png\n",
    "    raise ValueError(f'No file for {image}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_collection = []\n",
    "for annotation_file in annotation_files:\n",
    "    base_path = os.path.basename(annotation_file)\n",
    "    name, extension = os.path.splitext(base_path)\n",
    "    with open(annotation_file) as r:\n",
    "        full_image_path =  get_image_path(name)\n",
    "        im = Image.open(full_image_path)\n",
    "        in_file = []\n",
    "        for line in r:\n",
    "            values = []\n",
    "            string_values = line.split()\n",
    "            class_id = int(string_values[0])\n",
    "            if class_id not in ids_to_keep:\n",
    "                continue\n",
    "            values.append(full_image_path)\n",
    "            x,y,w,h = from_yolo_to_values(*[float(f) for f in string_values[1:]], im.size)\n",
    "            values.extend([ w, h ])\n",
    "            values.append( classes[class_id])\n",
    "            values.extend([ x, y, x+w, y+h ])\n",
    "            in_file.append(values)\n",
    "    in_collection.extend(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(in_collection, columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(test), type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(get_data_file('interim', 'train.csv'))\n",
    "test.to_csv(get_data_file('interim', 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is possible to use [Swaini's script](https://raw.githubusercontent.com/Swaini/object_detection_retraining/master/generate_tfrecord.py), located in `src/external/generate_tfrecord.py`, usage, from the root of this repo:\n",
    "\n",
    "**Do not forget to edit the file `generate_tfrecord.py` to add all your classes**\n",
    "\n",
    "```\n",
    "PYTHONPATH=src python src/external/generate_tfrecord.py --input_csv=data/interim/train.csv  --output_tfrecord=data/interim/train.record\n",
    "\n",
    "PYTHONPATH=src python src/external/generate_tfrecord.py --input_csv=data/interim/test.csv  --output_tfrecord=data/interim/test.record\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
